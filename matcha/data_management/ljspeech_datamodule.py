import torch
import pytorch_lightning as pl
from torch.utils.data import DataLoader
from torch.nn.utils.rnn import pad_sequence 
import os 

from matcha.data_management.ljspeechDataset import LJSpeechDataset

class LJSpeechDataModule(pl.LightningDataModule):
    def __init__(self, data_dir, batch_size=16, num_workers=4):
        super().__init__()
        self.data_dir = data_dir # Dossier contenant train.txt et val.txt
        self.batch_size = batch_size
        self.num_workers = num_workers

    def setup(self, stage=None):
        # Chargement direct depuis les fichiers générés par votre script ljspeech.py
        self.train_ds = LJSpeechDataset(os.path.join(self.data_dir, "train.txt"))
        self.val_ds = LJSpeechDataset(os.path.join(self.data_dir, "val.txt"))

    def train_dataloader(self):
        return DataLoader(
    self.train_ds,               # 1. Dataset
    batch_size=self.batch_size,   # 2. Taille du batch
    shuffle=True,                 # 3. Mélange des données
    num_workers=self.num_workers, # 4. Nombre de processus de chargement
    pin_memory=True,              # 5. Optimisation mémoire pour GPU
    collate_fn=self.collate)     # 6. Fonction de collation personnalisée voir juste en dessous


    def val_dataloader(self):
        return DataLoader(self.val_ds, batch_size=self.batch_size, 
                          num_workers=self.num_workers, collate_fn=self.collate)
    
    def collate(self, batch):
        """
        Organise les données en batch en ajoutant du padding.
        """
        # 1. Extraire les éléments du batch
        # x: IDs de texte, y: Spectrogrammes de Mel
        x = [item["x"] for item in batch]
        y = [item["y"] for item in batch]
        x_lengths = torch.tensor([item["x_lengths"] for item in batch])
        y_lengths = torch.tensor([item["y_lengths"] for item in batch])

        # 2. Padding du texte (x)
        # batch_first=True donne une forme [Batch, Longueur_max]
        x_padded = pad_sequence(x, batch_first=True, padding_value=0)

        # 3. Padding de l'audio (y)
        # y est [Canaux_Mel, Temps]. On doit padder sur la dimension Temps (index 1).
        # On transpose pour utiliser pad_sequence, puis on revient à la forme initiale.
        y_padded = pad_sequence([item.transpose(0, 1) for item in y], 
                                batch_first=True, padding_value=0).transpose(1, 2)

        return {
            "x": x_padded,
            "x_lengths": x_lengths,
            "y": y_padded,
            "y_lengths": y_lengths
        }